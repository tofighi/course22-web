# Ghassem Tofighi

:::{.callout-tip}
## New!

We just launched a new >30 hour video course for more experienced students:

[Practical Deep Learning for Coders part 2: *Deep Learning Foundations to Stable Diffusion*](Lessons/part2.qmd)
:::

## Data Storage

Data sourcing and data storage go hand-in-hand and it is necessary to store data in a format that facilitates easy access and processing. Depending on the use case, there are various kinds of data storage systems that can be used to store your datasets. Some examples are shown in @tbl-databases.

  ----------------------------------------------------------------------------
                 **Database**        **Data Warehouse**    **Data Lake**
  -------------- ------------------- --------------------- -------------------
  **Purpose**    Operational and     Analytical            Analytical
                 transactional

  **Data type**  Structured          Structured            Structured,
                                                           semi-structured
                                                           and/or unstructured

  **Scale**      Small to large      Large volumes of      Large volumes of
                 volumes of data     integrated data       diverse data

**Examples**   MySQL               Google BigQuery,      Google Cloud
                                     Amazon Redshift,      Storage, AWS S3,
                                     Microsoft Azure       Azure Data Lake
                                     Synapse.              Storage
  ----------------------------------------------------------------------------

  : Comparative overview of database, data warehouse, and data lake. {#tbl-databases}

## Table

| Precision  | Pros                                                      | Cons                                             |
|------------|-----------------------------------------------------------|--------------------------------------------------|
| **FP32** (Floating Point 32-bit) | Standard precision used in most deep learning frameworks.<br/> High accuracy due to ample representational capacity.<br/> Well-suited for training | High memory usage.<br/> Slower inference times compared to quantized models.<br/> Higher energy consumption. |
| **FP16** (Floating Point 16-bit) | Reduces memory usage compared to FP32.<br/> Speeds up computations on hardware that supports FP16.<br/> Often used in mixed-precision training to balance speed and accuracy. | Lower representational capacity compared to FP32.<br/> Risk of numerical instability in some models or layers. |
| **INT8** (8-bit Integer)         | Significantly reduced memory footprint compared to floating-point representations.<br/> Faster inference if hardware supports INT8 computations.<br/> Suitable for many post-training quantization scenarios. | Quantization can lead to some accuracy loss.<br/> Requires careful calibration during quantization to minimize accuracy degradation. |
| **INT4** (4-bit Integer)         | Even lower memory usage than INT8.<br/> Further speed-up potential for inference. | Higher risk of accuracy loss compared to INT8.<br/> Calibration during quantization becomes more critical. |
| **Binary**                       | Minimal memory footprint (only 1 bit per parameter).<br/> Extremely fast inference due to bitwise operations.<br/> Power efficient. | Significant accuracy drop for many tasks.<br/> Complex training dynamics due to extreme quantization. |
| **Ternary**                      | Low memory usage but slightly more than binary.<br/> Offers a middle ground between representation and efficiency. | Accuracy might still be lower than higher precision models.<br/> Training dynamics can be complex. |

### Efficiency Comparisons

There is an abundance of models in the ecosystem, each boasting its unique strengths and idiosyncrasies. However, pure model accuracy figures or training and inference speeds don't paint the complete picture. When we dive deeper into comparative analyses, several critical nuances emerge.

Often, we encounter the delicate balance between accuracy and efficiency. For instance, while a dense deep learning model and a lightweight MobileNet variant might both excel in image classification, their computational demands could be at two extremes. This differentiation is especially pronounced when comparing deployments on resource-abundant cloud servers versus constrained TinyML devices. In many real-world scenarios, the marginal gains in accuracy could be overshadowed by the inefficiencies of a resource-intensive model.

Moreover, the optimal model choice isn't always universal but often depends on the specifics of an application. Consider object detection: a model that excels in general scenarios might falter in niche environments like detecting manufacturing defects on a factory floor. This adaptability—or the lack of it—can dictate a model's real-world utility.

Another important consideration is the relationship between model complexity and its practical benefits. Take voice-activated assistants as an example such as "Alexa" or "OK Google." While a complex model might demonstrate a marginally superior understanding of user speech, if it's slower to respond than a simpler counterpart, the user experience could be compromised. Thus, adding layers or parameters doesn't always equate to better real-world outcomes.

Furthermore, while benchmark datasets, such as ImageNet [@russakovsky2015imagenet], COCO [@lin2014microsoft], Visual Wake Words [@chowdhery2019visual], Google Speech Commands [@warden2018speech], etc. provide a standardized performance metric, they might not capture the diversity and unpredictability of real-world data. Two facial recognition models with similar benchmark scores might exhibit varied competencies when faced with diverse ethnic backgrounds or challenging lighting conditions. Such disparities underscore the importance of robustness and consistency across varied data. For example, @fig-stoves from the Dollar Street dataset shows stove images across extreme monthly incomes. So if a model was trained on pictures of stoves found in wealth countries only, it will fail to recognize stoves from poorer regions.

![Objects, such as stoves, have different shapes and technological levels in different regions. A model that is not trained on diverse datasets might perform well on a benchmark but fail in real-world applications. Source: Dollar Street stove images.](https://pbs.twimg.com/media/DmUyPSSW0AAChGa.jpg){#fig-stoves}

In essence, a thorough comparative analysis transcends numerical metrics. It's a holistic assessment, intertwined with real-world applications, costs, and the intricate subtleties that each model brings to the table. This is why it becomes important to have standard benchmarks and metrics that are widely established and adopted by the community.



## Formulas

- $\pi \approx 3.14159$
- $\pm \, 0.2$
- $\dfrac{0}{1} \neq \infty$
- $0 < x < 1$
- $0 \leq x \leq 1$
- $x \geq 10$
- $\forall \, x \in (1,2)$
- $\exists \, x \notin [0,1]$
- $A \subset B$
- $A \subseteq B$
- $A \cup B$
- $A \cap B$
- $X \implies Y$
- $X \impliedby Y$
- $a \to b$
- $a \longrightarrow b$
- $a \Rightarrow b$
- $a \Longrightarrow b$
- $a \propto b$

$$\color{red}{X \sim Normal \; (\mu,\sigma^2)}$$


